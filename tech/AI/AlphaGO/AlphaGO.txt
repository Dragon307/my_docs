
----------------------------------------------------------------------------

深度解读 AlphaGo 算法原理

http://blog.csdn.net/songrotek/article/details/51065143

深度解读AlphaGo

----------------------------------------------------------------------------

近期看到AlphaGo算法最清晰的解读

https://yq.aliyun.com/articles/53737

摘要：来看看人工智能专家同时又是围棋高手的如何解读AlphaGo算法的。

有配图，比较直观和易于理解。

----------------------------------------------------------------------------

解密Google Deepmind AlphaGo围棋算法：真人工智能来自于哪里？ 

http://blog.csdn.net/songrotek/article/details/50610684

简单点评：通俗易懂的介绍了 4 个阶段的神经网络的过程与作用。


深度神经网络是AlphaGo的”大脑“，我们先把它当做一个黑匣子，有输入端，也有输出端，中间具体怎么处理先不考虑。那么AlphaGo的”大脑“实际上分成了四大部分：

    Rollout Policy 快速感知”脑“：用于快速的感知围棋的盘面，获取较优的下棋选择，类似于人观察盘面获得的第一反应，准确度不高
    SL Policy Network 深度模仿”脑“：通过人类6-9段高手的棋局来进行模仿学习得到的脑区。这个深度模仿“脑”能够根据盘面产生类似人类棋手的走法。
    RL Policy Network 自学成长“脑”：以深度模仿“脑”为基础，通过不断的与之前的“自己”训练提高下棋的水平。
    Value Network 全局分析“脑”：利用自学成长“脑”学习对整个盘面的赢面判断，实现从全局分析整个棋局。

所以，AlphaGo的“大脑”实际上有四个脑区，每个脑区的功能不一样，但对比一下发现这些能力基本对于人类棋手下棋所需的不同思维，既包含局部的计算，也包含全局的分析。其中的Policy Network用于具体每一步棋的优劣判断，而Value Network则对整个棋局进行形势的判断。


----------------------------------------------------------------------------

技术分析|AlphaGo赢了围棋 人工智能就此崛起？

http://tech.163.com/16/0310/09/BHPNPO5J00094P0U.html

MCTS搜索策略

比较详细的介绍了 MCTS（Monte Carlo Tree Search）蒙特卡洛搜索算法的原理和具体过程。

MCTS算法是一个多轮迭代算法，每一轮迭代都会以此经历四个阶段：Selection，Expansion，Simulation和Back Propagation。


----------------------------------------------------------------------------

2017-10-26 20:23

----------------------------------------------------------------------------

深度解读 AlphaGo 算法原理

http://blog.csdn.net/songrotek/article/details/51065143

一篇比较完整的关于最出版的 AlphaGo 的原理和分析，几乎可以复制一个 AlphaGo 了，非常推荐。19x19x48 的特征维度，使用卷积神经网络CNN。

注：该文最后的一些推荐文章里也还有一些有意义的文章，可以翻阅一下。

AlphaGo 算法最清晰的解读

http://blog.csdn.net/caozl218/article/details/72824068

其实算不上清晰，但有一些细节，虽然可能细节并不一定正确，但可以参考一下，也还不错。

----------------------------------------------------------------------------

